{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Marketing Dataset-UCI Machine learning reporsitory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import preprocessing\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('bank-additional-full.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label encoding of Education and One-hot encoding of categorical fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_engineering(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def fit(self, X=data, y=None):\n",
    "        df=X.copy()\n",
    "        if('education' in df.columns):\n",
    "            df.education=preprocessing.LabelEncoder().fit_transform(df.education)\n",
    "        cols=[]\n",
    "        for i in df.columns:\n",
    "            if(df[i].dtype=='O'):\n",
    "                cols.append(i)\n",
    "        data_dummies=pd.get_dummies(df,prefix=cols,columns=cols)\n",
    "        self.data_columns=data_dummies.columns\n",
    "        return self\n",
    "        \n",
    "\n",
    "    \n",
    "    def transform(self,X=data):\n",
    "        df=X.copy()\n",
    "        if('education' in df.columns):\n",
    "            df.education=preprocessing.LabelEncoder().fit_transform(df.education)\n",
    "        cols=[]\n",
    "        for i in df.columns:\n",
    "            if(df[i].dtype=='O'):\n",
    "                cols.append(i)\n",
    "        data_dummies=pd.get_dummies(df,prefix=cols,columns=cols)\n",
    "        data_dummies=data_dummies.reindex(columns = self.data_columns, fill_value=0)\n",
    "        df=df.drop(cols,axis=1)\n",
    "        x = pd.concat([df, data_dummies], axis=1)\n",
    "        x=x.loc[:,~x.columns.duplicated()]\n",
    "        return x\n",
    "    def transform_y(data):\n",
    "        y_dict={\n",
    "            'yes':1,\n",
    "            'no':0\n",
    "        }\n",
    "        data=data.map(y_dict)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinal encoding of Education and One-hot encoding of categorical fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_engineering(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def fit(self, X=data, y=None):\n",
    "        data=X.copy()\n",
    "        edu_dict={\n",
    "        'unknown':0,\n",
    "        'illiterate':1,\n",
    "\n",
    "        'basic.4y':2,\n",
    "        'basic.6y':3,\n",
    "        'basic.9y':4, \n",
    "        'high.school':5, \n",
    "           'professional.course':6,\n",
    "        'university.degree':7\n",
    "        }\n",
    "        data['education']=data['education'].map(edu_dict)\n",
    "        cols=[]\n",
    "        cols=[]\n",
    "        for i in data.columns:\n",
    "            if(data[i].dtype=='O'):\n",
    "                cols.append(i)\n",
    "        data_dummies=pd.get_dummies(data,prefix=cols,columns=cols)\n",
    "        self.data_columns=data_dummies.columns\n",
    "        return self\n",
    "        \n",
    "\n",
    "    \n",
    "    def transform(self,X=data):\n",
    "        data=X.copy()\n",
    "        edu_dict={\n",
    "        'unknown':0,\n",
    "        'basic.4y':1,\n",
    "        'basic.6y':2,\n",
    "        'basic.9y':3, \n",
    "        'high.school':4, \n",
    "        'illiterate':5,\n",
    "           'professional.course':6,\n",
    "        'university.degree':7\n",
    "        }\n",
    "        data['education']=data['education'].map(edu_dict)\n",
    "        cols=[]\n",
    "        for i in data.columns:\n",
    "            if(data[i].dtype=='O'):\n",
    "                cols.append(i)\n",
    "        data_dummies=pd.get_dummies(data,prefix=cols,columns=cols)\n",
    "        data_dummies=data_dummies.reindex(columns = self.data_columns, fill_value=0)\n",
    "        data=data.drop(cols,axis=1)\n",
    "        x = pd.concat([data, data_dummies], axis=1)\n",
    "        x=x.loc[:,~x.columns.duplicated()]\n",
    "        return x\n",
    "    def transform_y(data):\n",
    "        y_dict={\n",
    "            'yes':1,\n",
    "            'no':0\n",
    "        }\n",
    "        data=data.map(y_dict)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "          'roc_auc':make_scorer(roc_auc_score)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strarified K fold Cross-validation on Pipeline including  Feature Engineering and Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def decision_tree_pipeline(X,y):\n",
    "    cv=StratifiedKFold(n_splits=10, random_state=0, shuffle=True)\n",
    "    pipeline = Pipeline([('Pre-processing',Feature_engineering()),('Tree',DecisionTreeClassifier(random_state=0,max_depth=5))])\n",
    "    scores = cross_validate(pipeline,X,y,cv=cv,scoring=scoring,return_train_score=True,return_estimator=True)\n",
    "    print(\"Mean training ROC AUC score: \",np.mean(scores['train_roc_auc']),\" and mean testing ROC AUC score: \",np.mean(scores['test_roc_auc']))\n",
    "    print(\"Mean training accuracy score: \",np.mean(scores['train_accuracy']),\" and mean testing accuracy score: \",np.mean(scores['test_accuracy']))\n",
    "    print(\"Mean training recall score: \",np.mean(scores['train_recall']),\" and mean testing recall score: \",np.mean(scores['test_recall']))\n",
    "    print(\"Mean training precision score: \",np.mean(scores['train_precision']),\" and mean testing precision score: \",np.mean(scores['test_precision']))\n",
    "    print(\"Mean training f1 score: \",np.mean(scores['train_f1_score']),\" and mean testing f1 score: \",np.mean(scores['test_f1_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean training ROC AUC score:  0.7477277851778261  and mean testing ROC AUC score:  0.740179047828701\n",
      "Mean training accuracy score:  0.9173977325278024  and mean testing accuracy score:  0.9142228866076383\n",
      "Mean training recall score:  0.5287116858237548  and mean testing recall score:  0.5155172413793102\n",
      "Mean training precision score:  0.6693454922049513  and mean testing precision score:  0.6519437351574204\n",
      "Mean training f1 score:  0.5900704096553948  and mean testing f1 score:  0.5748945970917563\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('bank-additional-full.csv',sep=';')\n",
    "X=data.iloc[:,:-1]\n",
    "y=Feature_engineering.transform_y(data.iloc[:,-1])\n",
    "decision_tree_pipeline(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strarified K fold Cross-validation on pipeline including Feature Engineering and Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " def random_forest_pipeline(X,y):\n",
    "    cv=StratifiedKFold(n_splits=10, random_state=0, shuffle=True)\n",
    "    pipeline = Pipeline([('Pre-processing',Feature_engineering()),('forest',RandomForestClassifier(n_estimators=100,random_state=42,max_depth=5))])\n",
    "    scores = cross_validate(pipeline,X,y,cv=cv,scoring=scoring,return_train_score=True,return_estimator =True)\n",
    "    \n",
    "    print(\"Mean training ROC AUC score: \",np.mean(scores['train_roc_auc']),\" and mean testing ROC AUC score: \",np.mean(scores['test_roc_auc']))\n",
    "    print(\"Mean training accuracy score: \",np.mean(scores['train_accuracy']),\" and mean testing accuracy score: \",np.mean(scores['test_accuracy']))\n",
    "    print(\"Mean training recall score: \",np.mean(scores['train_recall']),\" and mean testing recall score: \",np.mean(scores['test_recall']))\n",
    "    print(\"Mean training precision score: \",np.mean(scores['train_precision']),\" and mean testing precision score: \",np.mean(scores['test_precision']))\n",
    "    print(\"Mean training f1 score: \",np.mean(scores['train_f1_score']),\" and mean testing f1 score: \",np.mean(scores['test_f1_score']))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, use all the columns to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean training ROC AUC score:  0.5968306729125565  and mean testing ROC AUC score:  0.5936002924291877\n",
      "Mean training accuracy score:  0.9041036781319226  and mean testing accuracy score:  0.9028601273360838\n",
      "Mean training recall score:  0.20019157088122602  and mean testing recall score:  0.19439655172413792\n",
      "Mean training precision score:  0.7956746953504387  and mean testing precision score:  0.7766896102472217\n",
      "Mean training f1 score:  0.3198699293295462  and mean testing f1 score:  0.3105786397261269\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('bank-additional-full.csv',sep=';')\n",
    "X=data.iloc[:,:-1]\n",
    "y=Feature_engineering.transform_y(data.iloc[:,-1])\n",
    "scores=random_forest_pipeline(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating the feature  importance dataframe for each of the K estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances=pd.DataFrame()\n",
    "for idx,estimator in enumerate(scores['estimator']):\n",
    "    ft_estimator=pd.DataFrame({\n",
    "        'columns order for estimator_{}'.format(idx):Feature_engineering().fit_transform(X).columns,\n",
    "        'importance_estimator_{}'.format(idx):estimator.steps[1][1].feature_importances_}).sort_values(['importance_estimator_{}'.format(idx)], ascending=False)\n",
    "    ft_estimator.reset_index(inplace=True,drop=True)\n",
    "    feature_importances=pd.concat([feature_importances,ft_estimator],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns order for estimator_0</th>\n",
       "      <th>importance_estimator_0</th>\n",
       "      <th>columns order for estimator_1</th>\n",
       "      <th>importance_estimator_1</th>\n",
       "      <th>columns order for estimator_2</th>\n",
       "      <th>importance_estimator_2</th>\n",
       "      <th>columns order for estimator_3</th>\n",
       "      <th>importance_estimator_3</th>\n",
       "      <th>columns order for estimator_4</th>\n",
       "      <th>importance_estimator_4</th>\n",
       "      <th>columns order for estimator_5</th>\n",
       "      <th>importance_estimator_5</th>\n",
       "      <th>columns order for estimator_6</th>\n",
       "      <th>importance_estimator_6</th>\n",
       "      <th>columns order for estimator_7</th>\n",
       "      <th>importance_estimator_7</th>\n",
       "      <th>columns order for estimator_8</th>\n",
       "      <th>importance_estimator_8</th>\n",
       "      <th>columns order for estimator_9</th>\n",
       "      <th>importance_estimator_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.269182</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.261184</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.263069</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.275963</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.241223</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.258903</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.266456</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.258463</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.272630</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.265974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nr.employed</td>\n",
       "      <td>0.160323</td>\n",
       "      <td>nr.employed</td>\n",
       "      <td>0.157813</td>\n",
       "      <td>nr.employed</td>\n",
       "      <td>0.152880</td>\n",
       "      <td>nr.employed</td>\n",
       "      <td>0.150097</td>\n",
       "      <td>nr.employed</td>\n",
       "      <td>0.150411</td>\n",
       "      <td>nr.employed</td>\n",
       "      <td>0.157141</td>\n",
       "      <td>nr.employed</td>\n",
       "      <td>0.172784</td>\n",
       "      <td>nr.employed</td>\n",
       "      <td>0.160745</td>\n",
       "      <td>nr.employed</td>\n",
       "      <td>0.152073</td>\n",
       "      <td>nr.employed</td>\n",
       "      <td>0.155214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>euribor3m</td>\n",
       "      <td>0.124312</td>\n",
       "      <td>euribor3m</td>\n",
       "      <td>0.132867</td>\n",
       "      <td>euribor3m</td>\n",
       "      <td>0.137112</td>\n",
       "      <td>euribor3m</td>\n",
       "      <td>0.130091</td>\n",
       "      <td>euribor3m</td>\n",
       "      <td>0.136773</td>\n",
       "      <td>euribor3m</td>\n",
       "      <td>0.125494</td>\n",
       "      <td>euribor3m</td>\n",
       "      <td>0.123476</td>\n",
       "      <td>euribor3m</td>\n",
       "      <td>0.120444</td>\n",
       "      <td>euribor3m</td>\n",
       "      <td>0.121993</td>\n",
       "      <td>euribor3m</td>\n",
       "      <td>0.117847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pdays</td>\n",
       "      <td>0.090368</td>\n",
       "      <td>pdays</td>\n",
       "      <td>0.092798</td>\n",
       "      <td>pdays</td>\n",
       "      <td>0.085341</td>\n",
       "      <td>pdays</td>\n",
       "      <td>0.086034</td>\n",
       "      <td>pdays</td>\n",
       "      <td>0.085837</td>\n",
       "      <td>pdays</td>\n",
       "      <td>0.101099</td>\n",
       "      <td>pdays</td>\n",
       "      <td>0.090715</td>\n",
       "      <td>pdays</td>\n",
       "      <td>0.087696</td>\n",
       "      <td>pdays</td>\n",
       "      <td>0.088454</td>\n",
       "      <td>pdays</td>\n",
       "      <td>0.089227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cons.conf.idx</td>\n",
       "      <td>0.064923</td>\n",
       "      <td>poutcome_success</td>\n",
       "      <td>0.067264</td>\n",
       "      <td>cons.conf.idx</td>\n",
       "      <td>0.065717</td>\n",
       "      <td>cons.conf.idx</td>\n",
       "      <td>0.066146</td>\n",
       "      <td>cons.conf.idx</td>\n",
       "      <td>0.074167</td>\n",
       "      <td>emp.var.rate</td>\n",
       "      <td>0.060419</td>\n",
       "      <td>cons.conf.idx</td>\n",
       "      <td>0.061635</td>\n",
       "      <td>poutcome_success</td>\n",
       "      <td>0.071095</td>\n",
       "      <td>cons.conf.idx</td>\n",
       "      <td>0.066484</td>\n",
       "      <td>poutcome_success</td>\n",
       "      <td>0.068600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  columns order for estimator_0  importance_estimator_0  \\\n",
       "0                      duration                0.269182   \n",
       "1                   nr.employed                0.160323   \n",
       "2                     euribor3m                0.124312   \n",
       "3                         pdays                0.090368   \n",
       "4                 cons.conf.idx                0.064923   \n",
       "\n",
       "  columns order for estimator_1  importance_estimator_1  \\\n",
       "0                      duration                0.261184   \n",
       "1                   nr.employed                0.157813   \n",
       "2                     euribor3m                0.132867   \n",
       "3                         pdays                0.092798   \n",
       "4              poutcome_success                0.067264   \n",
       "\n",
       "  columns order for estimator_2  importance_estimator_2  \\\n",
       "0                      duration                0.263069   \n",
       "1                   nr.employed                0.152880   \n",
       "2                     euribor3m                0.137112   \n",
       "3                         pdays                0.085341   \n",
       "4                 cons.conf.idx                0.065717   \n",
       "\n",
       "  columns order for estimator_3  importance_estimator_3  \\\n",
       "0                      duration                0.275963   \n",
       "1                   nr.employed                0.150097   \n",
       "2                     euribor3m                0.130091   \n",
       "3                         pdays                0.086034   \n",
       "4                 cons.conf.idx                0.066146   \n",
       "\n",
       "  columns order for estimator_4  importance_estimator_4  \\\n",
       "0                      duration                0.241223   \n",
       "1                   nr.employed                0.150411   \n",
       "2                     euribor3m                0.136773   \n",
       "3                         pdays                0.085837   \n",
       "4                 cons.conf.idx                0.074167   \n",
       "\n",
       "  columns order for estimator_5  importance_estimator_5  \\\n",
       "0                      duration                0.258903   \n",
       "1                   nr.employed                0.157141   \n",
       "2                     euribor3m                0.125494   \n",
       "3                         pdays                0.101099   \n",
       "4                  emp.var.rate                0.060419   \n",
       "\n",
       "  columns order for estimator_6  importance_estimator_6  \\\n",
       "0                      duration                0.266456   \n",
       "1                   nr.employed                0.172784   \n",
       "2                     euribor3m                0.123476   \n",
       "3                         pdays                0.090715   \n",
       "4                 cons.conf.idx                0.061635   \n",
       "\n",
       "  columns order for estimator_7  importance_estimator_7  \\\n",
       "0                      duration                0.258463   \n",
       "1                   nr.employed                0.160745   \n",
       "2                     euribor3m                0.120444   \n",
       "3                         pdays                0.087696   \n",
       "4              poutcome_success                0.071095   \n",
       "\n",
       "  columns order for estimator_8  importance_estimator_8  \\\n",
       "0                      duration                0.272630   \n",
       "1                   nr.employed                0.152073   \n",
       "2                     euribor3m                0.121993   \n",
       "3                         pdays                0.088454   \n",
       "4                 cons.conf.idx                0.066484   \n",
       "\n",
       "  columns order for estimator_9  importance_estimator_9  \n",
       "0                      duration                0.265974  \n",
       "1                   nr.employed                0.155214  \n",
       "2                     euribor3m                0.117847  \n",
       "3                         pdays                0.089227  \n",
       "4              poutcome_success                0.068600  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>Enter specific columns obtained from feature importance dataframe and train the model on them.\n",
    "<p>In this case we find the columns 'pdays', 'duration', 'euribor3m', 'cons.conf.idx', 'nr.employed' as the most important features</p></blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean training ROC AUC score:  0.6898457971188521  and mean testing ROC AUC score:  0.6829390088032005\n",
      "Mean training accuracy score:  0.9139231531588564  and mean testing accuracy score:  0.9114791308735114\n",
      "Mean training recall score:  0.4005986590038314  and mean testing recall score:  0.38793103448275856\n",
      "Mean training precision score:  0.7091834662469677  and mean testing precision score:  0.6924859828756309\n",
      "Mean training f1 score:  0.5114896909042359  and mean testing f1 score:  0.4964042471037581\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('bank-additional-full.csv',sep=';')\n",
    "y=Feature_engineering.transform_y(data.iloc[:,-1])\n",
    "imp_cols=['pdays','duration','euribor3m','cons.conf.idx','nr.employed'] #columns obtained from feature importances\n",
    "X=data.loc[:,imp_cols]\n",
    "scores=random_forest_pipeline(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Note:</b> We see an improvement in training score and testing score on using those specific columns</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K-fold CV on Pipeline inclduing Feature Engineering, SMOTE , Undersampling and Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def random_forest_pipeline(X,y):\n",
    "    from imblearn.pipeline import Pipeline\n",
    "\n",
    "    over = SMOTE(sampling_strategy=0.2)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "    pipeline = Pipeline([('Pre-processing',Feature_engineering()),('over', over),('under', under),('forest',RandomForestClassifier(n_estimators=50,random_state=42,max_depth=5))])\n",
    "    pipeline = pipeline.fit(X,y)\n",
    "    scores = cross_validate(pipeline,X,y,cv=10,scoring=scoring,return_train_score=True,return_estimator =True)\n",
    "    \n",
    "    print(\"Mean training ROC AUC score: \",np.mean(scores['train_roc_auc']),\" and mean testing ROC AUC score: \",np.mean(scores['test_roc_auc']))\n",
    "    print(\"Mean training accuracy score: \",np.mean(scores['train_accuracy']),\" and mean testing accuracy score: \",np.mean(scores['test_accuracy']))\n",
    "    print(\"Mean training recall score: \",np.mean(scores['train_recall']),\" and mean testing recall score: \",np.mean(scores['test_recall']))\n",
    "    print(\"Mean training precision score: \",np.mean(scores['train_precision']),\" and mean testing precision score: \",np.mean(scores['test_precision']))\n",
    "    print(\"Mean training f1 score: \",np.mean(scores['train_f1_score']),\" and mean testing f1 AUC score: \",np.mean(scores['test_f1_score']))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, use all the columns to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\surta\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\surta\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean training ROC AUC score:  0.7737775469342563  and mean testing ROC AUC score:  0.5694342785898108\n",
      "Mean training accuracy score:  0.8994043047027918  and mean testing accuracy score:  0.7399345845270281\n",
      "Mean training recall score:  0.6116139846743296  and mean testing recall score:  0.3493534482758621\n",
      "Mean training precision score:  0.5584836848900292  and mean testing precision score:  0.2296286206943939\n",
      "Mean training f1 score:  0.5802079050388178  and mean testing f1 AUC score:  0.16393654602435465\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('bank-additional-full.csv',sep=';')\n",
    "\n",
    "X=data.iloc[:,:-1]\n",
    "y=Feature_engineering.transform_y(data.iloc[:,-1])\n",
    "scores=random_forest_pipeline(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>To deal with class imbalance , we oversample the minority class and undersampling the majority class</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating the feature importance dataframe for each of the K estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances=pd.DataFrame()\n",
    "for idx,estimator in enumerate(scores['estimator']):\n",
    "    ft_estimator=pd.DataFrame({\n",
    "        'columns order for estimator_{}'.format(idx):Feature_engineering().fit_transform(X).columns,\n",
    "        'importance_estimator_{}'.format(idx):estimator.steps[3][1].feature_importances_}).sort_values(['importance_estimator_{}'.format(idx)], ascending=False)\n",
    "    ft_estimator.reset_index(inplace=True,drop=True)\n",
    "    feature_importances=pd.concat([feature_importances,ft_estimator],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns order for estimator_0</th>\n",
       "      <th>importance_estimator_0</th>\n",
       "      <th>columns order for estimator_1</th>\n",
       "      <th>importance_estimator_1</th>\n",
       "      <th>columns order for estimator_2</th>\n",
       "      <th>importance_estimator_2</th>\n",
       "      <th>columns order for estimator_3</th>\n",
       "      <th>importance_estimator_3</th>\n",
       "      <th>columns order for estimator_4</th>\n",
       "      <th>importance_estimator_4</th>\n",
       "      <th>columns order for estimator_5</th>\n",
       "      <th>importance_estimator_5</th>\n",
       "      <th>columns order for estimator_6</th>\n",
       "      <th>importance_estimator_6</th>\n",
       "      <th>columns order for estimator_7</th>\n",
       "      <th>importance_estimator_7</th>\n",
       "      <th>columns order for estimator_8</th>\n",
       "      <th>importance_estimator_8</th>\n",
       "      <th>columns order for estimator_9</th>\n",
       "      <th>importance_estimator_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.249740</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.227809</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.283479</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.290085</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.238586</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.274160</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.258069</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.273783</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.290195</td>\n",
       "      <td>duration</td>\n",
       "      <td>0.239863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nr.employed</td>\n",
       "      <td>0.133652</td>\n",
       "      <td>nr.employed</td>\n",
       "      <td>0.161080</td>\n",
       "      <td>nr.employed</td>\n",
       "      <td>0.128312</td>\n",
       "      <td>nr.employed</td>\n",
       "      <td>0.157779</td>\n",
       "      <td>nr.employed</td>\n",
       "      <td>0.182015</td>\n",
       "      <td>euribor3m</td>\n",
       "      <td>0.146327</td>\n",
       "      <td>nr.employed</td>\n",
       "      <td>0.141536</td>\n",
       "      <td>emp.var.rate</td>\n",
       "      <td>0.125462</td>\n",
       "      <td>euribor3m</td>\n",
       "      <td>0.133896</td>\n",
       "      <td>nr.employed</td>\n",
       "      <td>0.153424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emp.var.rate</td>\n",
       "      <td>0.132328</td>\n",
       "      <td>emp.var.rate</td>\n",
       "      <td>0.130583</td>\n",
       "      <td>emp.var.rate</td>\n",
       "      <td>0.119435</td>\n",
       "      <td>euribor3m</td>\n",
       "      <td>0.108097</td>\n",
       "      <td>euribor3m</td>\n",
       "      <td>0.105906</td>\n",
       "      <td>nr.employed</td>\n",
       "      <td>0.091755</td>\n",
       "      <td>emp.var.rate</td>\n",
       "      <td>0.124653</td>\n",
       "      <td>euribor3m</td>\n",
       "      <td>0.123736</td>\n",
       "      <td>nr.employed</td>\n",
       "      <td>0.125390</td>\n",
       "      <td>euribor3m</td>\n",
       "      <td>0.147359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>euribor3m</td>\n",
       "      <td>0.118986</td>\n",
       "      <td>euribor3m</td>\n",
       "      <td>0.103376</td>\n",
       "      <td>euribor3m</td>\n",
       "      <td>0.101825</td>\n",
       "      <td>pdays</td>\n",
       "      <td>0.089523</td>\n",
       "      <td>emp.var.rate</td>\n",
       "      <td>0.075492</td>\n",
       "      <td>pdays</td>\n",
       "      <td>0.090582</td>\n",
       "      <td>euribor3m</td>\n",
       "      <td>0.089779</td>\n",
       "      <td>nr.employed</td>\n",
       "      <td>0.103634</td>\n",
       "      <td>emp.var.rate</td>\n",
       "      <td>0.124370</td>\n",
       "      <td>emp.var.rate</td>\n",
       "      <td>0.113032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pdays</td>\n",
       "      <td>0.078129</td>\n",
       "      <td>cons.conf.idx</td>\n",
       "      <td>0.080187</td>\n",
       "      <td>pdays</td>\n",
       "      <td>0.077510</td>\n",
       "      <td>emp.var.rate</td>\n",
       "      <td>0.078808</td>\n",
       "      <td>pdays</td>\n",
       "      <td>0.074169</td>\n",
       "      <td>emp.var.rate</td>\n",
       "      <td>0.089587</td>\n",
       "      <td>pdays</td>\n",
       "      <td>0.077862</td>\n",
       "      <td>cons.conf.idx</td>\n",
       "      <td>0.078057</td>\n",
       "      <td>cons.price.idx</td>\n",
       "      <td>0.068022</td>\n",
       "      <td>cons.conf.idx</td>\n",
       "      <td>0.102100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  columns order for estimator_0  importance_estimator_0  \\\n",
       "0                      duration                0.249740   \n",
       "1                   nr.employed                0.133652   \n",
       "2                  emp.var.rate                0.132328   \n",
       "3                     euribor3m                0.118986   \n",
       "4                         pdays                0.078129   \n",
       "\n",
       "  columns order for estimator_1  importance_estimator_1  \\\n",
       "0                      duration                0.227809   \n",
       "1                   nr.employed                0.161080   \n",
       "2                  emp.var.rate                0.130583   \n",
       "3                     euribor3m                0.103376   \n",
       "4                 cons.conf.idx                0.080187   \n",
       "\n",
       "  columns order for estimator_2  importance_estimator_2  \\\n",
       "0                      duration                0.283479   \n",
       "1                   nr.employed                0.128312   \n",
       "2                  emp.var.rate                0.119435   \n",
       "3                     euribor3m                0.101825   \n",
       "4                         pdays                0.077510   \n",
       "\n",
       "  columns order for estimator_3  importance_estimator_3  \\\n",
       "0                      duration                0.290085   \n",
       "1                   nr.employed                0.157779   \n",
       "2                     euribor3m                0.108097   \n",
       "3                         pdays                0.089523   \n",
       "4                  emp.var.rate                0.078808   \n",
       "\n",
       "  columns order for estimator_4  importance_estimator_4  \\\n",
       "0                      duration                0.238586   \n",
       "1                   nr.employed                0.182015   \n",
       "2                     euribor3m                0.105906   \n",
       "3                  emp.var.rate                0.075492   \n",
       "4                         pdays                0.074169   \n",
       "\n",
       "  columns order for estimator_5  importance_estimator_5  \\\n",
       "0                      duration                0.274160   \n",
       "1                     euribor3m                0.146327   \n",
       "2                   nr.employed                0.091755   \n",
       "3                         pdays                0.090582   \n",
       "4                  emp.var.rate                0.089587   \n",
       "\n",
       "  columns order for estimator_6  importance_estimator_6  \\\n",
       "0                      duration                0.258069   \n",
       "1                   nr.employed                0.141536   \n",
       "2                  emp.var.rate                0.124653   \n",
       "3                     euribor3m                0.089779   \n",
       "4                         pdays                0.077862   \n",
       "\n",
       "  columns order for estimator_7  importance_estimator_7  \\\n",
       "0                      duration                0.273783   \n",
       "1                  emp.var.rate                0.125462   \n",
       "2                     euribor3m                0.123736   \n",
       "3                   nr.employed                0.103634   \n",
       "4                 cons.conf.idx                0.078057   \n",
       "\n",
       "  columns order for estimator_8  importance_estimator_8  \\\n",
       "0                      duration                0.290195   \n",
       "1                     euribor3m                0.133896   \n",
       "2                   nr.employed                0.125390   \n",
       "3                  emp.var.rate                0.124370   \n",
       "4                cons.price.idx                0.068022   \n",
       "\n",
       "  columns order for estimator_9  importance_estimator_9  \n",
       "0                      duration                0.239863  \n",
       "1                   nr.employed                0.153424  \n",
       "2                     euribor3m                0.147359  \n",
       "3                  emp.var.rate                0.113032  \n",
       "4                 cons.conf.idx                0.102100  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>Enter specific columns obtained from feature importance dataframe and train the model on them.\n",
    "<p>In this case we find the columns 'pdays','duration','euribor3m','cons.conf.idx','nr.employed' as the most important features</p></blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean training ROC AUC score:  0.8751391897919738  and mean testing ROC AUC score:  0.5653974169191868\n",
      "Mean training accuracy score:  0.8945215592997735  and mean testing accuracy score:  0.7095628993254468\n",
      "Mean training recall score:  0.8501197318007663  and mean testing recall score:  0.3793103448275862\n",
      "Mean training precision score:  0.5212519618042899  and mean testing precision score:  0.2606082738092446\n",
      "Mean training f1 score:  0.6456533933802951  and mean testing f1 AUC score:  0.19805887718483675\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('bank-additional-full.csv',sep=';')\n",
    "y=Feature_engineering.transform_y(data.iloc[:,-1])\n",
    "imp_cols=['pdays','duration','euribor3m','cons.conf.idx','nr.employed'] #columns obtained from feature importances\n",
    "X=data.loc[:,imp_cols]\n",
    "scores=random_forest_pipeline(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Note:</b> We see an improvement in training score and testing score on using those specific columns</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
